{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "3VgpKIh1ycAZ"
      },
      "id": "3VgpKIh1ycAZ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q1OWLKXhI-CW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "id": "q1OWLKXhI-CW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: news sentiment classification with Bert model**"
      ],
      "metadata": {
        "id": "qb-s6Rqg1EXR"
      },
      "id": "qb-s6Rqg1EXR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load news data from apple as training set"
      ],
      "metadata": {
        "id": "uKGzhfCY0-io"
      },
      "id": "uKGzhfCY0-io"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7sApCG4Rx7sN"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('stock_news/aapl.csv')\n",
        "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "7sApCG4Rx7sN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pre-trained Bert Model"
      ],
      "metadata": {
        "id": "nPnBiN6k1S3g"
      },
      "id": "nPnBiN6k1S3g"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "model = BertModel.from_pretrained('bert-base-cased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sdsulftynLt",
        "outputId": "be66625a-0cfc-48df-ea12-c7799de7e929"
      },
      "id": "8sdsulftynLt",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-classification task\n",
        "Use Bert to classify news to 2 categories: Positive, Negative"
      ],
      "metadata": {
        "id": "2hepEv9m8MQL"
      },
      "id": "2hepEv9m8MQL"
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_classification import Bert_Classifier\n",
        "bert_clf = Bert_Classifier(model, tokenizer, device, df, 2)\n",
        "bert_clf.train()\n",
        "bert_clf.test()"
      ],
      "metadata": {
        "id": "voGVHEoFyhE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c16cf92-1f34-4274-ea19-80b93165d93f"
      },
      "id": "voGVHEoFyhE9",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of BERT mode on news 2-classification task is: 0.6427104722792608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-classification task\n",
        "Use Bert to classify news to 3 categories: Positive, Negative, Neutral"
      ],
      "metadata": {
        "id": "YhhLy7i18QE1"
      },
      "id": "YhhLy7i18QE1"
    },
    {
      "cell_type": "code",
      "source": [
        "from bert_classification import Bert_Classifier\n",
        "bert_clf3 = Bert_Classifier(model, tokenizer, device, df, 3)\n",
        "bert_clf3.train()\n",
        "bert_clf3.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-hD26SZ8V06",
        "outputId": "23aa6958-b3b4-4010-8b98-a316380327d1"
      },
      "id": "e-hD26SZ8V06",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of BERT mode on news 3-classification task is: 0.4574948665297741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: news sentiment classification with T5 model**"
      ],
      "metadata": {
        "id": "pHw6Db970cnb"
      },
      "id": "pHw6Db970cnb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "load pretrained t5 model"
      ],
      "metadata": {
        "id": "WR75gmHu0pPq"
      },
      "id": "WR75gmHu0pPq"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eldP_usrx7sM"
      },
      "outputs": [],
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small',use_cache='False')"
      ],
      "id": "eldP_usrx7sM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-classification task\n",
        "Use T5 to classify news to 2 categories: Positive, Negative"
      ],
      "metadata": {
        "id": "sFH_88k56on_"
      },
      "id": "sFH_88k56on_"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kN7qBvBex7sO",
        "outputId": "87e9338a-190b-4554-fd74-098dd69752d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 8 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    1 | 0.76187 | 0:05:41\n",
            "\n",
            "======== Epoch 2 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    2 | 0.22212 | 0:05:41\n",
            "\n",
            "======== Epoch 3 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    3 | 0.21838 | 0:05:41\n",
            "\n",
            "======== Epoch 4 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    4 | 0.21338 | 0:05:41\n",
            "\n",
            "======== Epoch 5 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    5 | 0.20963 | 0:05:41\n",
            "\n",
            "======== Epoch 6 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    6 | 0.20664 | 0:05:41\n",
            "\n",
            "======== Epoch 7 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    7 | 0.20214 | 0:05:41\n",
            "\n",
            "======== Epoch 8 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    8 | 0.19962 | 0:05:41\n"
          ]
        }
      ],
      "source": [
        "from T5_classification import T5_Classifier\n",
        "t5_clf = T5_Classifier(model, tokenizer, device, df, 2)\n",
        "t5_clf.train()"
      ],
      "id": "kN7qBvBex7sO"
    },
    {
      "cell_type": "code",
      "source": [
        "test_stat, test_result = t5_clf.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFt0BdsQHHSt",
        "outputId": "8227d8be-ca10-43ac-e103-53bb5ddc97a4"
      },
      "id": "SFt0BdsQHHSt",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Testing...\n",
            "  Batch    40  of    203.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    203.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    203.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    203.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    203.    Elapsed: 0:01:18.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_stat)\n",
        "test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Ytn4NphvKDZH",
        "outputId": "4c6a3049-70aa-4884-944f-8cce86bfa3a9"
      },
      "id": "Ytn4NphvKDZH",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Test Loss': 0.2059948617234606, 'Test PPL.': 1.2287468903377718, 'Test Acc.': 0.6645768025078367, 'Test F1': 0.6920763777542512}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44274de8-72b5-4db5-b58b-dc8fb235f219\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2430</th>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2431</th>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2432</th>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2433</th>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2434</th>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2435 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44274de8-72b5-4db5-b58b-dc8fb235f219')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44274de8-72b5-4db5-b58b-dc8fb235f219 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44274de8-72b5-4db5-b58b-dc8fb235f219');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     predicted    actual\n",
              "0     positive  negative\n",
              "1     positive  negative\n",
              "2     positive  negative\n",
              "3     negative  positive\n",
              "4     negative  positive\n",
              "...        ...       ...\n",
              "2430  negative  negative\n",
              "2431  positive  positive\n",
              "2432  positive  positive\n",
              "2433  positive  positive\n",
              "2434  positive  positive\n",
              "\n",
              "[2435 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-classification task\n",
        "Use T5 to classify news to 3 categories: Positive, Negative, Neutral"
      ],
      "metadata": {
        "id": "pbSpUFzc0xgL"
      },
      "id": "pbSpUFzc0xgL"
    },
    {
      "cell_type": "code",
      "source": [
        "t5_clf3 = T5_Classifier(model, tokenizer, device, df, 3)\n",
        "t5_clf3.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z6eXfcO8DHO",
        "outputId": "079234ad-a5da-42c7-9a5d-e7d347b8d474"
      },
      "id": "0z6eXfcO8DHO",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 8 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    1 | 0.40769 | 0:05:41\n",
            "\n",
            "======== Epoch 2 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    2 | 0.35968 | 0:05:41\n",
            "\n",
            "======== Epoch 3 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    3 | 0.34533 | 0:05:41\n",
            "\n",
            "======== Epoch 4 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    4 | 0.33502 | 0:05:41\n",
            "\n",
            "======== Epoch 5 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    5 | 0.32103 | 0:05:41\n",
            "\n",
            "======== Epoch 6 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    6 | 0.31555 | 0:05:41\n",
            "\n",
            "======== Epoch 7 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    7 | 0.30443 | 0:05:41\n",
            "\n",
            "======== Epoch 8 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    609.\n",
            "  Batch    80  of    609.\n",
            "  Batch   120  of    609.\n",
            "  Batch   160  of    609.\n",
            "  Batch   200  of    609.\n",
            "  Batch   240  of    609.\n",
            "  Batch   280  of    609.\n",
            "  Batch   320  of    609.\n",
            "  Batch   360  of    609.\n",
            "  Batch   400  of    609.\n",
            "  Batch   440  of    609.\n",
            "  Batch   480  of    609.\n",
            "  Batch   520  of    609.\n",
            "  Batch   560  of    609.\n",
            "  Batch   600  of    609.\n",
            "\n",
            "summary results\n",
            "epoch | trn loss | trn time \n",
            "    8 | 0.30192 | 0:05:41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_stat, test_result = t5_clf.test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM6jnxmvNAbw",
        "outputId": "603f5645-565d-4ae5-95cb-9321fc062d6f"
      },
      "id": "nM6jnxmvNAbw",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Testing...\n",
            "  Batch    40  of    203.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    203.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    203.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    203.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    203.    Elapsed: 0:01:18.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_stat)\n",
        "test_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "wlchFn5oNCah",
        "outputId": "3372e936-e4a8-48f8-fd89-99632537c7c8"
      },
      "id": "wlchFn5oNCah",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Test Loss': 0.3839951871063909, 'Test PPL.': 1.4681383756711799, 'Test Acc.': 0.4345051500223913, 'Test F1': 0.3620878628358344}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8541b510-bab7-4e0d-9623-ad4fd89ac1ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2430</th>\n",
              "      <td>neutral</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2431</th>\n",
              "      <td>neutral</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2432</th>\n",
              "      <td>negative</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2433</th>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2434</th>\n",
              "      <td>positive</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2435 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8541b510-bab7-4e0d-9623-ad4fd89ac1ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8541b510-bab7-4e0d-9623-ad4fd89ac1ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8541b510-bab7-4e0d-9623-ad4fd89ac1ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     predicted    actual\n",
              "0     negative  positive\n",
              "1     positive  positive\n",
              "2     positive  negative\n",
              "3     negative  negative\n",
              "4      neutral  positive\n",
              "...        ...       ...\n",
              "2430   neutral  negative\n",
              "2431   neutral  positive\n",
              "2432  negative  negative\n",
              "2433  positive  positive\n",
              "2434  positive  negative\n",
              "\n",
              "[2435 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "news_process.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}